{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a869b-fe0d-4d54-a000-7753ff11191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Auto-generate YOLO dataset from video using pseudo-labeling and synthetic augmentation.\n",
    "\n",
    "Author: Никита\n",
    "Date: 2025-11-06\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "# ==================== КОНФИГУРАЦИЯ ====================\n",
    "class Config:\n",
    "    \"\"\"Configuration parameters for dataset creation.\"\"\"\n",
    "    VIDEO_PATH: str = \"crowd.mp4\"\n",
    "    OUTPUT_DIR: str = \"dataset\"\n",
    "    TRAIN_RATIO: float = 0.8\n",
    "    FRAME_SKIP: int = 1\n",
    "    MIN_CONF: float = 0.4\n",
    "    SYNTHETIC_RATIO: float = 0.5  # +50% synthetic images to train\n",
    "    MAX_COPY_PASTE: int = 2\n",
    "    SEED: int = 42\n",
    "\n",
    "\n",
    "# ==================== УТИЛИТЫ ====================\n",
    "def setup_directories(output_dir: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create dataset directory structure.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Root dataset directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: Paths to image and label directories.\n",
    "    \"\"\"\n",
    "    paths = {\n",
    "        \"img_train\": os.path.join(output_dir, \"images\", \"train\"),\n",
    "        \"img_val\": os.path.join(output_dir, \"images\", \"val\"),\n",
    "        \"lbl_train\": os.path.join(output_dir, \"labels\", \"train\"),\n",
    "        \"lbl_val\": os.path.join(output_dir, \"labels\", \"val\"),\n",
    "    }\n",
    "    for p in paths.values():\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def extract_frames(video_path: str, frame_skip: int = 1) -> List[Tuple[int, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Extract frames from video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to input video.\n",
    "        frame_skip (int): Extract every Nth frame.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[int, np.ndarray]]: List of (original_index, frame).\n",
    "    \"\"\"\n",
    "    if not Path(video_path).exists():\n",
    "        raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video: {video_path}\")\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "\n",
    "    print(f\"Video: {total_frames} frames, {duration:.1f}s, {fps:.1f} FPS\")\n",
    "\n",
    "    frames = []\n",
    "    frame_idx = 0\n",
    "    saved_idx = 0\n",
    "\n",
    "    print(\"Extracting frames...\")\n",
    "    with tqdm(total=total_frames, unit=\"frame\", colour=\"blue\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if frame_idx % frame_skip == 0:\n",
    "                frames.append((saved_idx, frame.copy()))\n",
    "                saved_idx += 1\n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(frames)} frames\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "def pseudo_label_frames(\n",
    "    frames: List[Tuple[int, np.ndarray]],\n",
    "    model: YOLO,\n",
    "    min_conf: float = 0.4\n",
    ") -> List[Tuple[int, np.ndarray, List[str]]]:\n",
    "    \"\"\"\n",
    "    Run YOLO inference and convert to YOLO format labels.\n",
    "\n",
    "    Args:\n",
    "        frames: List of (idx, frame).\n",
    "        model: Loaded YOLO model.\n",
    "        min_conf: Minimum confidence.\n",
    "\n",
    "    Returns:\n",
    "        List of (idx, frame, labels_list).\n",
    "    \"\"\"\n",
    "    print(\"Pseudo-labeling frames with YOLO...\")\n",
    "    labeled = []\n",
    "\n",
    "    for idx, (_, frame) in enumerate(tqdm(frames, unit=\"frame\")):\n",
    "        h, w = frame.shape[:2]\n",
    "        results = model(frame, conf=min_conf, classes=[0], verbose=False)[0]\n",
    "        labels = []\n",
    "\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = box.conf.item()\n",
    "\n",
    "            # YOLO format: class x_center y_center width height (normalized)\n",
    "            x_center = (x1 + x2) / 2 / w\n",
    "            y_center = (y1 + y2) / 2 / h\n",
    "            bw = (x2 - x1) / w\n",
    "            bh = (y2 - y1) / h\n",
    "            labels.append(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "        labeled.append((idx, frame, labels))\n",
    "\n",
    "    return labeled\n",
    "\n",
    "\n",
    "def split_and_save(\n",
    "    labeled_frames: List[Tuple[int, np.ndarray, List[str]]],\n",
    "    paths: Dict[str, str],\n",
    "    train_ratio: float\n",
    ") -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Split into train/val and save images + labels.\n",
    "\n",
    "    Args:\n",
    "        labeled_frames: List of labeled data.\n",
    "        paths: Directory paths.\n",
    "        train_ratio: Fraction for training.\n",
    "\n",
    "    Returns:\n",
    "        train_indices, val_indices.\n",
    "    \"\"\"\n",
    "    random.seed(Config.SEED)\n",
    "    random.shuffle(labeled_frames)\n",
    "    split_idx = int(len(labeled_frames) * train_ratio)\n",
    "\n",
    "    train_data = labeled_frames[:split_idx]\n",
    "    val_data = labeled_frames[split_idx:]\n",
    "\n",
    "    def save_set(data, img_dir, lbl_dir, start_idx):\n",
    "        indices = []\n",
    "        for i, (_, frame, labels) in enumerate(data):\n",
    "            global_idx = start_idx + i\n",
    "            img_name = f\"frame_{global_idx:06d}.jpg\"\n",
    "            lbl_name = f\"frame_{global_idx:06d}.txt\"\n",
    "\n",
    "            cv2.imwrite(os.path.join(img_dir, img_name), frame)\n",
    "            with open(os.path.join(lbl_dir, lbl_name), \"w\") as f:\n",
    "                if labels:\n",
    "                    f.write(\"\\n\".join(labels))\n",
    "            indices.append(global_idx)\n",
    "        return indices\n",
    "\n",
    "    print(\"Saving base dataset...\")\n",
    "    train_indices = save_set(train_data, paths[\"img_train\"], paths[\"lbl_train\"], 0)\n",
    "    val_indices = save_set(val_data, paths[\"img_val\"], paths[\"lbl_val\"], len(train_data))\n",
    "\n",
    "    return train_indices, val_indices\n",
    "\n",
    "\n",
    "def generate_synthetic(\n",
    "    train_indices: List[int],\n",
    "    paths: Dict[str, str],\n",
    "    model: YOLO,\n",
    "    synth_count: int\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate synthetic images using augmentation + copy-paste.\n",
    "\n",
    "    Args:\n",
    "        train_indices: List of training image indices.\n",
    "        paths: Dataset paths.\n",
    "        model: YOLO model (for re-detection if needed).\n",
    "        synth_count: Number of synthetic images to generate.\n",
    "    \"\"\"\n",
    "    if synth_count <= 0:\n",
    "        return\n",
    "\n",
    "    # Augmentation pipeline\n",
    "    aug = A.Compose([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "        A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
    "        A.MotionBlur(blur_limit=3, p=0.3),\n",
    "        A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.2),\n",
    "        A.RandomRain(p=0.2),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomScale(scale_limit=0.2, p=0.5),\n",
    "        A.Rotate(limit=15, p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"]))\n",
    "\n",
    "    def copy_paste(src_img, src_labels, dst_img, max_pastes=2):\n",
    "        h, w = src_img.shape[:2]\n",
    "        people = []\n",
    "        for label in src_labels:\n",
    "            parts = list(map(float, label.split()))\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            _, cx, cy, bw, bh = parts\n",
    "            x1 = int((cx - bw/2) * w)\n",
    "            y1 = int((cy - bh/2) * h)\n",
    "            x2 = int((cx + bw/2) * w)\n",
    "            y2 = int((cy + bh/2) * h)\n",
    "            if x1 < x2 and y1 < y2:\n",
    "                person = src_img[y1:y2, x1:x2]\n",
    "                if person.size > 0:\n",
    "                    people.append((person, (cx, cy, bw, bh)))\n",
    "\n",
    "        new_labels = []\n",
    "        pasted = 0\n",
    "        dst_h, dst_w = dst_img.shape[:2]\n",
    "        for person, (cx, cy, bw, bh) in random.sample(people, k=min(len(people), max_pastes)):\n",
    "            if pasted >= max_pastes:\n",
    "                break\n",
    "            ph, pw = person.shape[:2]\n",
    "            scale = random.uniform(0.6, 1.4)\n",
    "            nw, nh = int(pw * scale), int(ph * scale)\n",
    "            if nw <= 0 or nh <= 0:\n",
    "                continue\n",
    "            person_resized = cv2.resize(person, (nw, nh))\n",
    "\n",
    "            x = random.randint(0, max(1, dst_w - nw))\n",
    "            y = random.randint(0, max(1, dst_h - nh))\n",
    "\n",
    "            dst_img[y:y+nh, x:x+nw] = person_resized\n",
    "\n",
    "            new_cx = (x + nw/2) / dst_w\n",
    "            new_cy = (y + nh/2) / dst_h\n",
    "            new_bw = nw / dst_w\n",
    "            new_bh = nh / dst_h\n",
    "            new_labels.append(f\"0 {new_cx:.6f} {new_cy:.6f} {new_bw:.6f} {new_bh:.6f}\")\n",
    "            pasted += 1\n",
    "\n",
    "        return dst_img, new_labels\n",
    "\n",
    "    print(f\"Generating {synth_count} synthetic images...\")\n",
    "    synth_idx = len(train_indices)\n",
    "\n",
    "    for _ in tqdm(range(synth_count), unit=\"img\"):\n",
    "        src_idx = random.choice(train_indices)\n",
    "        src_img_path = os.path.join(paths[\"img_train\"], f\"frame_{src_idx:06d}.jpg\")\n",
    "        src_lbl_path = os.path.join(paths[\"lbl_train\"], f\"frame_{src_idx:06d}.txt\")\n",
    "\n",
    "        src_img = cv2.imread(src_img_path)\n",
    "        with open(src_lbl_path, \"r\") as f:\n",
    "            src_labels = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        # Augmentation\n",
    "        bboxes = [list(map(float, l.split()[1:])) for l in src_labels]\n",
    "        class_labels = [\"person\"] * len(bboxes)\n",
    "\n",
    "        if bboxes:\n",
    "            augmented = aug(image=src_img, bboxes=bboxes, class_labels=class_labels)\n",
    "            aug_img = augmented[\"image\"]\n",
    "            aug_bboxes = augmented[\"bboxes\"]\n",
    "        else:\n",
    "            aug_img = src_img\n",
    "            aug_bboxes = []\n",
    "\n",
    "        # Copy-paste\n",
    "        final_img, paste_labels = copy_paste(src_img, src_labels, aug_img.copy(), Config.MAX_COPY_PASTE)\n",
    "\n",
    "        # Combine labels\n",
    "        final_labels = [f\"0 {x:.6f} {y:.6f} {w:.6f} {h:.6f}\" for x, y, w, h in aug_bboxes]\n",
    "        final_labels.extend(paste_labels)\n",
    "\n",
    "        # Save\n",
    "        synth_name = f\"synth_{synth_idx:06d}\"\n",
    "        cv2.imwrite(os.path.join(paths[\"img_train\"], f\"{synth_name}.jpg\"), final_img)\n",
    "        with open(os.path.join(paths[\"lbl_train\"], f\"{synth_name}.txt\"), \"w\") as f:\n",
    "            if final_labels:\n",
    "                f.write(\"\\n\".join(final_labels))\n",
    "        synth_idx += 1\n",
    "\n",
    "    print(f\"Added {synth_count} synthetic images to train set\")\n",
    "\n",
    "\n",
    "def write_data_yaml(output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Create data.yaml for YOLO training.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): Dataset root.\n",
    "    \"\"\"\n",
    "    yaml_content = f\"\"\"path: {Path(output_dir).resolve()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 1\n",
    "names: ['person']\n",
    "\"\"\"\n",
    "    yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
    "    with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(yaml_content)\n",
    "    print(f\"data.yaml created: {yaml_path}\")\n",
    "\n",
    "\n",
    "# ==================== ОСНОВНАЯ ФУНКЦИЯ ====================\n",
    "def create_dataset(\n",
    "    video_path: str = Config.VIDEO_PATH,\n",
    "    output_dir: str = Config.OUTPUT_DIR,\n",
    "    frame_skip: int = Config.FRAME_SKIP,\n",
    "    min_conf: float = Config.MIN_CONF,\n",
    "    train_ratio: float = Config.TRAIN_RATIO,\n",
    "    synthetic_ratio: float = Config.SYNTHETIC_RATIO\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Main function: create full YOLO dataset from video.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to generated data.yaml\n",
    "    \"\"\"\n",
    "    random.seed(Config.SEED)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # 1. Setup\n",
    "    paths = setup_directories(output_dir)\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # 2. Extract frames\n",
    "    frames = extract_frames(video_path, frame_skip)\n",
    "\n",
    "    # 3. Pseudo-label\n",
    "    labeled = pseudo_label_frames(frames, model, min_conf)\n",
    "\n",
    "    # 4. Split & save\n",
    "    train_indices, val_indices = split_and_save(labeled, paths, train_ratio)\n",
    "\n",
    "    # 5. Synthetic data\n",
    "    synth_count = int(len(train_indices) * synthetic_ratio)\n",
    "    generate_synthetic(train_indices, paths, model, synth_count)\n",
    "\n",
    "    # 6. data.yaml\n",
    "    write_data_yaml(output_dir)\n",
    "\n",
    "    # Summary\n",
    "    train_imgs = len(os.listdir(paths[\"img_train\"]))\n",
    "    val_imgs = len(os.listdir(paths[\"img_val\"]))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATASET CREATED SUCCESSFULLY!\")\n",
    "    print(f\"Dataset: {output_dir}\")\n",
    "    print(f\"Train: {train_imgs} images\")\n",
    "    print(f\"Val: {val_imgs} images\")\n",
    "    print(f\"data.yaml: {os.path.join(output_dir, 'data.yaml')}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return str(output_path / \"data.yaml\")\n",
    "\n",
    "\n",
    "# ==================== ТОЧКА ВХОДА ====================\n",
    "def main() -> None:\n",
    "    \"\"\"Entry point.\"\"\"\n",
    "    data_yaml = create_dataset()\n",
    "    print(f\"\\nГотово! Запустите обучение:\")\n",
    "    print(f\"   python train.py  # (из предыдущего задания)\")\n",
    "    print(f\"   или:\")\n",
    "    print(f\"   yolo train data={data_yaml} model=yolov8s.pt epochs=100 imgsz=640\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_4",
   "language": "python",
   "name": "venv_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
