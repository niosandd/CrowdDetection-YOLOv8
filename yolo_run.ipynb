{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d6adce-77e3-459d-9af1-c68fff956cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: 1920x1080, 29.97 FPS, 705 frames\n",
      "Processing video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 705/705 [00:33<00:00, 21.29frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved to output_video.mp4\n",
      "Processed 705 frames with detection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Crowd Detection: Detects people in input video using YOLOv8 and saves annotated output.\n",
    "\n",
    "Author: Никита\n",
    "Date: 2025-11-06\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_model(model_path: str = \"yolov8n.pt\") -> YOLO:\n",
    "    \"\"\"\n",
    "    Load pre-trained YOLOv8 model. Downloads if not present.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to model weights (e.g., 'yolov8n.pt').\n",
    "\n",
    "    Returns:\n",
    "        YOLO: Loaded model instance.\n",
    "    \"\"\"\n",
    "    model_path = str(Path(model_path))\n",
    "    if not Path(model_path).exists():\n",
    "        print(f\"Model {model_path} not found. Downloading from Ultralytics...\")\n",
    "    return YOLO(model_path)\n",
    "\n",
    "\n",
    "def draw_detections(\n",
    "    frame: np.ndarray,\n",
    "    results,\n",
    "    conf_threshold: float = 0.4,\n",
    "    color: Tuple[int, int, int] = (0, 255, 0),\n",
    "    thickness: int = 2\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw bounding boxes and labels (person + confidence) on the frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.ndarray): Input BGR frame.\n",
    "        results: YOLO inference results.\n",
    "        conf_threshold (float): Minimum confidence to display.\n",
    "        color (Tuple[int, int, int]): BGR color for bounding box and label.\n",
    "        thickness (int): Line thickness for bounding box.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Annotated frame.\n",
    "    \"\"\"\n",
    "    annotated_frame = frame.copy()\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            conf = box.conf.item()\n",
    "            if conf < conf_threshold:\n",
    "                continue\n",
    "\n",
    "            cls_id = int(box.cls.item())\n",
    "            if cls_id != 0:  # 0 = 'person' in COCO\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            label = f\"person {conf:.2f}\"\n",
    "\n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "            # Draw label background\n",
    "            label_size, baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            label_y = y1 - 10 if y1 - 10 > 10 else y1 + 20 + baseline\n",
    "            cv2.rectangle(\n",
    "                annotated_frame,\n",
    "                (x1, label_y - label_size[1] - 10),\n",
    "                (x1 + label_size[0], label_y),\n",
    "                color,\n",
    "                -1\n",
    "            )\n",
    "\n",
    "            # Draw label text\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                label,\n",
    "                (x1, label_y - 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 0),\n",
    "                1,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "\n",
    "    return annotated_frame\n",
    "\n",
    "\n",
    "def process_video(\n",
    "    video_path: str,\n",
    "    output_path: str,\n",
    "    model: YOLO,\n",
    "    conf_threshold: float = 0.4,\n",
    "    frame_skip: int = 1\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process video: detect people, annotate, save output.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to input video.\n",
    "        output_path (str): Path to save annotated video.\n",
    "        model (YOLO): Preloaded YOLO model.\n",
    "        conf_threshold (float): Confidence threshold for detection.\n",
    "        frame_skip (int): Process every Nth frame (1 = all frames).\n",
    "    \"\"\"\n",
    "    video_path = str(Path(video_path))\n",
    "    output_path = str(Path(output_path))\n",
    "\n",
    "    if not Path(video_path).exists():\n",
    "        raise FileNotFoundError(f\"Input video not found: {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video file: {video_path}\")\n",
    "\n",
    "    # Video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"Input: {width}x{height}, {fps:.2f} FPS, {total_frames} frames\")\n",
    "\n",
    "    # Output writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_idx = 0\n",
    "    processed_count = 0\n",
    "\n",
    "    print(\"Processing frames...\")\n",
    "    with tqdm(total=total_frames, unit=\"frame\", colour=\"green\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            current_frame = frame.copy()\n",
    "\n",
    "            if frame_idx % frame_skip == 0:\n",
    "                # Run inference\n",
    "                results = model(frame, conf=conf_threshold, classes=[0], verbose=False)[0]\n",
    "                # Annotate\n",
    "                annotated_frame = draw_detections(current_frame, [results], conf_threshold)\n",
    "                processed_count += 1\n",
    "            else:\n",
    "                annotated_frame = current_frame\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            frame_idx += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Output saved: {output_path}\")\n",
    "    print(f\"Processed {processed_count} frames with detection.\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Entry point of the program.\"\"\"\n",
    "    video_input = \"crowd.mp4\"\n",
    "    video_output = \"output_video.mp4\"\n",
    "    model = load_model(\"yolov8n.pt\")\n",
    "\n",
    "    process_video(\n",
    "        video_path=video_input,\n",
    "        output_path=video_output,\n",
    "        model=model,\n",
    "        conf_threshold=0.4,\n",
    "        frame_skip=1\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1297602-4019-4126-b601-23c61fd8c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_4",
   "language": "python",
   "name": "venv_4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
